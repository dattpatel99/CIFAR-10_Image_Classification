{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info regarding dataset\n",
    "'''CIFAR is set of 60k images of 32 by 32 pixels on 3 channels'''\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10 # number of outputs\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2 # How much data to save for validation testing\n",
    "OPTIMIZER = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding and normalizing images\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "#Normalize\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Form the model/neural network\n",
    "'''\n",
    "# 32 feature maps/filters each of size 3x3, output == input in size, activation is ReLU\n",
    "model = Sequential() # Defining a model\n",
    "model.add(Conv2D(32, (3,3),padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "# Max polling with size 2x2 and adding dropout of 25%\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 1.8211 - accuracy: 0.3576 - val_loss: 1.4514 - val_accuracy: 0.4903\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.4249 - accuracy: 0.4917 - val_loss: 1.3660 - val_accuracy: 0.5223\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 1.2958 - accuracy: 0.5423 - val_loss: 1.2431 - val_accuracy: 0.5578\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 1.2158 - accuracy: 0.5691 - val_loss: 1.2191 - val_accuracy: 0.5790\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 1.1528 - accuracy: 0.5936 - val_loss: 1.1591 - val_accuracy: 0.5991\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.0904 - accuracy: 0.6179 - val_loss: 1.1043 - val_accuracy: 0.6182\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 21s 69ms/step - loss: 1.0491 - accuracy: 0.6311 - val_loss: 1.0359 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.0107 - accuracy: 0.6458 - val_loss: 1.0546 - val_accuracy: 0.6316\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.9725 - accuracy: 0.6597 - val_loss: 1.0517 - val_accuracy: 0.6422\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.9388 - accuracy: 0.6709 - val_loss: 1.0131 - val_accuracy: 0.6509\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 21s 67ms/step - loss: 0.9136 - accuracy: 0.6822 - val_loss: 1.0334 - val_accuracy: 0.6553\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.8812 - accuracy: 0.6919 - val_loss: 1.0140 - val_accuracy: 0.6590\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.8558 - accuracy: 0.7016 - val_loss: 1.0317 - val_accuracy: 0.6541\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 23s 74ms/step - loss: 0.8292 - accuracy: 0.7115 - val_loss: 1.0832 - val_accuracy: 0.6435\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.8108 - accuracy: 0.7172 - val_loss: 1.0319 - val_accuracy: 0.6620\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 0.7919 - accuracy: 0.7264 - val_loss: 1.0455 - val_accuracy: 0.6502\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7696 - accuracy: 0.7319 - val_loss: 1.0167 - val_accuracy: 0.6565\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7474 - accuracy: 0.7401 - val_loss: 1.0748 - val_accuracy: 0.6588\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 0.7302 - accuracy: 0.7455 - val_loss: 1.0991 - val_accuracy: 0.6546\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 22s 71ms/step - loss: 0.7110 - accuracy: 0.7541 - val_loss: 1.0713 - val_accuracy: 0.6716\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 1.0851 - accuracy: 0.6660\n",
      "Test score:  1.0851424932479858\n",
      "Test accuracy:  0.6660000085830688\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_json = model.to_json()\n",
    "open('assignment3_saved_model.json', 'w').write(model_json)\n",
    "model.save_weights('assignment3_saved_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm we have created this week can be used to create a smarter AI which takes spatial vectors into calculation while learning. This AI could be trained to distinguish animals, vehicles and people. The algorithm can be trained to identify different people using their unique facial characteristics. However, training the algorithm to distinguish people's face can have some ethical and privacy related issues.\n",
    " \n",
    "A major ethical issue that I found on training algorithms to distinguish faces is that due to inaccurate training data the algorithm is shown to develop a racial bias. The algorithm's ability to function properly depends on the training data it is provided. For instance, \"errors detected in the face recognition system were more common on dark-skinned faces, but fewer errors when matching light-skinned faces\" (Gangarapu, 2022). Additionally, National Institute of Standards and Technology (NIST) did an assessment on AI and facial recognition and found out that \" facial recognition technologies for 189 algorithms showed racial bias toward women of color\" (Gangarapu, 2022). Of course racial bias is not the only ethical issue with algorithms learning to distinguish faces.  \n",
    " \n",
    "Training algorithms to distinguish faces leads to another ethical and privacy issue, which is mass surveillance. Training the algorithm requires a large amount of data that needs to be stored somewhere. This creates a privacy concern that the facial data could be misused somewhere. Not only that, but based on the privacy concern \"people are worried about the use of technology for mass surveillance\"(Fox, 2020). Ethically, facial recognition could lead to mass surveillance which can compromise citizens' liberty and privacy rights(Gangarapu, 2022). Using the facial recognition system would help in a lot of ways like it has in China however, it would mean that the fundamental right of privacy for innocent people would be compromised every second they live.\n",
    " \n",
    "Overall, it is possible to use the algorithm we created to distinguish faces however, there are many ethical and privacy issues with doing so. The system can be used for mass surveillance leading to lack of privacy for innocent people. Further, the system could end up creating a racial bias due to improper training data which poses and ethical concern for the system.\n",
    " \n",
    "References:\n",
    "Gangarapu, K. R. (2022, January 25). Ethics of Facial Recognition: Key Issues and Solutions. Learn Hub. https://learn.g2.com/ethics-of-facial-recognition#:%7E:text=The%20top%20six%20ethical%20concerns,breaches%2C%20and%20inefficient%20legal%20support.\n",
    "Fox, H. (2020, October 1). 3 Privacy Concerns Around Facial Recognition Technology. Swiftlane. https://www.swiftlane.com/blog/facial-recognition-privacy-concerns/ "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cdcbf2f1a6b7a53ec24c1743f42bd4cf1969fd40fcad7cff48c73852883d4f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
